{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_ICP_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uJKsuiNRZRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZE_O-ZRa857",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6add907a-8510-4b31-fc82-a7874d9b5a04"
      },
      "source": [
        "!ls /usr/lib/jvm/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "default-java\t\t   java-11-openjdk-amd64     java-8-openjdk-amd64\n",
            "java-1.11.0-openjdk-amd64  java-1.8.0-openjdk-amd64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok2fnNbd-KH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0rSrOXq-e8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "d343c502-fbf7-418b-e29c-e2a9b039078a"
      },
      "source": [
        "!pip install pyspark\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/b0/bf9020b56492281b9c9d8aae8f44ff51e1bc91b3ef5a884385cb4e389a40/pyspark-3.0.0.tar.gz (204.7MB)\n",
            "\u001b[K     |████████████████████████████████| 204.7MB 64kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044184 sha256=ab63247198a5b4b8ce61e06fa8375f168ef087c51e719bfe009830545e4db1e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/27/4d/ddacf7143f8d5b76c45c61ee2e43d9f8492fc5a8e78ebd7d37\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyI9uFiqynEa",
        "colab_type": "text"
      },
      "source": [
        "Configuring a SparkSession\n",
        "\n",
        "The entry point to using Spark SQL is an object called SparkSession. It initiates a Spark Application which all the code for that Session will run on.\n",
        "\n",
        ".builder — gives access to Builder API which is used to configure the session .\n",
        "\n",
        ".master() — determines where the program will run; \"local[*]\" sets it to run locally on all cores but you can use \"local[1]\" to run on one core for example. In this case, our programs will be run on Google’s servers.\n",
        "\n",
        ".appName() — optional method to name the Spark Application\n",
        "\n",
        ".getOrCreate() — gets an existing SparkSession or creates new one if none exists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXFCPjS9ArVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"Big_Data_Application\").getOrCreate()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSRfg8l9z_Sr",
        "colab_type": "text"
      },
      "source": [
        "To open a local file on Google Colab you need to run the following code which will prompt you to select a file from your computer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nrU95Xpz_v4",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "eba09bb5-87b0-45e6-a4c2-f14644463ebf"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ef476ad4-24ba-4e45-b6ea-561516eb437d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ef476ad4-24ba-4e45-b6ea-561516eb437d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIOUY8Kozqi4",
        "colab_type": "text"
      },
      "source": [
        "Now load our data into a Spark DataFrame using the .read.csv()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVTWGQuWRff0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = spark.read.csv('test.csv',inferSchema=True, header=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gys5EUOG1kl0",
        "colab_type": "text"
      },
      "source": [
        "Data Exploration\n",
        "\n",
        "Now let’s move into understanding how we can get more familiar with our data!\n",
        "The first thing we can do is check the shape of of our DataFrame. Unlike Pandas, there is no dedicated method for this but we can use the .count() and .columns() to retrieve the information ourselves.\n",
        "The .count() method returns the number of rows in the DataFrame and .columns returns a list of column names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEflR3Cujk4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "433d3ea6-9e56-4088-9250-1fb0f137a0aa"
      },
      "source": [
        "data.count(), len(data.columns)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(418, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5H3T7yL2CfM",
        "colab_type": "text"
      },
      "source": [
        "Viewing DataFrames\n",
        "To view a DataFrame, use the .show() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbcH1jG_6qy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2a730d89-dfd6-4bb1-a6d7-e54a198bb25b"
      },
      "source": [
        "data.show(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
            "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch| Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
            "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0| 330911| 7.8292| null|       Q|\n",
            "|        893|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0| 363272|    7.0| null|       S|\n",
            "|        894|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0| 240276| 9.6875| null|       Q|\n",
            "|        895|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0| 315154| 8.6625| null|       S|\n",
            "|        896|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|3101298|12.2875| null|       S|\n",
            "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULPZM29a62gQ",
        "colab_type": "text"
      },
      "source": [
        "As you can see, running data.show(5) displayed the first 5 rows of our DataFrame, along with the header. Calling .show() with no parameters will return the first 20 records.\n",
        "\n",
        "\n",
        "Let’s see what our data is comprised of using the .printSchema() method (alternatively you can use .dtypes):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVnzZwIy7FkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9c663deb-387b-46be-ba1c-9b05731077ae"
      },
      "source": [
        "data.printSchema()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZL0J5So7QMp",
        "colab_type": "text"
      },
      "source": [
        "We can also selectively choose which columns we want to display with the .select() method.\n",
        "Included the truncate=False parameter that adjusts the size of columns to prevent values from being cut off"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maG7XThX7PMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a128eafa-f33a-472b-fc16-d52187ca6d7a"
      },
      "source": [
        "data.select(\"PassengerId\",\"Name\",\"Sex\").show(15, truncate=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+-------------------------------------------------------+------+\n",
            "|PassengerId|Name                                                   |Sex   |\n",
            "+-----------+-------------------------------------------------------+------+\n",
            "|892        |Kelly, Mr. James                                       |male  |\n",
            "|893        |Wilkes, Mrs. James (Ellen Needs)                       |female|\n",
            "|894        |Myles, Mr. Thomas Francis                              |male  |\n",
            "|895        |Wirz, Mr. Albert                                       |male  |\n",
            "|896        |Hirvonen, Mrs. Alexander (Helga E Lindqvist)           |female|\n",
            "|897        |Svensson, Mr. Johan Cervin                             |male  |\n",
            "|898        |Connolly, Miss. Kate                                   |female|\n",
            "|899        |Caldwell, Mr. Albert Francis                           |male  |\n",
            "|900        |Abrahim, Mrs. Joseph (Sophie Halaut Easu)              |female|\n",
            "|901        |Davies, Mr. John Samuel                                |male  |\n",
            "|902        |Ilieff, Mr. Ylio                                       |male  |\n",
            "|903        |Jones, Mr. Charles Cresson                             |male  |\n",
            "|904        |Snyder, Mrs. John Pillsbury (Nelle Stevenson)          |female|\n",
            "|905        |Howard, Mr. Benjamin                                   |male  |\n",
            "|906        |Chaffee, Mrs. Herbert Fuller (Carrie Constance Toogood)|female|\n",
            "+-----------+-------------------------------------------------------+------+\n",
            "only showing top 15 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaKRUdX471ka",
        "colab_type": "text"
      },
      "source": [
        "Summary Statistics/Information\n",
        "\n",
        "We can use the .describe() method to get summary statistics on columns of our choosing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45D_Paes7okq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4294845f-40b3-445c-c0a2-dc33392905e9"
      },
      "source": [
        "data.describe([\"Fare\",\"Age\"]).show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+------------------+\n",
            "|summary|              Fare|               Age|\n",
            "+-------+------------------+------------------+\n",
            "|  count|               417|               332|\n",
            "|   mean|  35.6271884892086|30.272590361445783|\n",
            "| stddev|55.907576179973844|14.181209235624424|\n",
            "|    min|               0.0|              0.17|\n",
            "|    max|          512.3292|              76.0|\n",
            "+-------+------------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiSaqQtA8VpA",
        "colab_type": "text"
      },
      "source": [
        "We might also want to get some information on what age groups are in the data and how they are distributed. We can use a groupBy() for this and sort it using .orderBy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6swXLFA8Tfe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1a84c85c-4858-4f88-d9f0-e47ac777dab3"
      },
      "source": [
        "data.groupBy(\"Age\").count().orderBy(\"count\", ascending=False).show(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-----+\n",
            "| Age|count|\n",
            "+----+-----+\n",
            "|null|   86|\n",
            "|24.0|   17|\n",
            "|21.0|   17|\n",
            "|22.0|   16|\n",
            "|30.0|   15|\n",
            "|18.0|   13|\n",
            "|27.0|   12|\n",
            "|26.0|   12|\n",
            "|23.0|   11|\n",
            "|25.0|   11|\n",
            "+----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEuwV7Rf88JP",
        "colab_type": "text"
      },
      "source": [
        "Filtering DataFrames\n",
        "\n",
        "Lets create a new DataFrame that has the null values for User_Score and User_Count, and the “tbd” values filtered out using the .filter() method.\n",
        "\n",
        "condition1 returns True for any record that does not have a null value in Age or in Fare. condition2 returns True for any record that does not have “female” in Sex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvFKH4k687aB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "badece51-a6e9-442f-8336-01895e205443"
      },
      "source": [
        "condition1 = (data.Age.isNotNull()) | (data.Fare.isNotNull())\n",
        "condition2 = data.Sex != 'female'\n",
        "data1 = data.filter(condition1).filter(condition2)\n",
        "data1.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+------+--------------------+----+----+-----+-----+----------+-------+-----+--------+\n",
            "|PassengerId|Pclass|                Name| Sex| Age|SibSp|Parch|    Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+------+--------------------+----+----+-----+-----+----------+-------+-----+--------+\n",
            "|        892|     3|    Kelly, Mr. James|male|34.5|    0|    0|    330911| 7.8292| null|       Q|\n",
            "|        894|     2|Myles, Mr. Thomas...|male|62.0|    0|    0|    240276| 9.6875| null|       Q|\n",
            "|        895|     3|    Wirz, Mr. Albert|male|27.0|    0|    0|    315154| 8.6625| null|       S|\n",
            "|        897|     3|Svensson, Mr. Joh...|male|14.0|    0|    0|      7538|  9.225| null|       S|\n",
            "|        899|     2|Caldwell, Mr. Alb...|male|26.0|    1|    1|    248738|   29.0| null|       S|\n",
            "|        901|     3|Davies, Mr. John ...|male|21.0|    2|    0| A/4 48871|  24.15| null|       S|\n",
            "|        902|     3|    Ilieff, Mr. Ylio|male|null|    0|    0|    349220| 7.8958| null|       S|\n",
            "|        903|     1|Jones, Mr. Charle...|male|46.0|    0|    0|       694|   26.0| null|       S|\n",
            "|        905|     2|Howard, Mr. Benjamin|male|63.0|    1|    0|     24065|   26.0| null|       S|\n",
            "|        908|     2|   Keane, Mr. Daniel|male|35.0|    0|    0|    233734|  12.35| null|       Q|\n",
            "|        909|     3|   Assaf, Mr. Gerios|male|21.0|    0|    0|      2692|  7.225| null|       C|\n",
            "|        912|     1|Rothschild, Mr. M...|male|55.0|    1|    0|  PC 17603|   59.4| null|       C|\n",
            "|        913|     3|Olsen, Master. Ar...|male| 9.0|    0|    1|   C 17368| 3.1708| null|       S|\n",
            "|        915|     1|Williams, Mr. Ric...|male|21.0|    0|    1|  PC 17597|61.3792| null|       C|\n",
            "|        917|     3|Robins, Mr. Alexa...|male|50.0|    1|    0| A/5. 3337|   14.5| null|       S|\n",
            "|        919|     3|   Daher, Mr. Shedid|male|22.5|    0|    0|      2698|  7.225| null|       C|\n",
            "|        920|     1|Brady, Mr. John B...|male|41.0|    0|    0|    113054|   30.5|  A21|       S|\n",
            "|        921|     3|   Samaan, Mr. Elias|male|null|    2|    0|      2662|21.6792| null|       C|\n",
            "|        922|     2|Louch, Mr. Charle...|male|50.0|    1|    0|SC/AH 3085|   26.0| null|       S|\n",
            "|        923|     2|Jefferys, Mr. Cli...|male|24.0|    2|    0|C.A. 31029|   31.5| null|       S|\n",
            "+-----------+------+--------------------+----+----+-----+-----+----------+-------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7wpgJ2X-Zs4",
        "colab_type": "text"
      },
      "source": [
        "Building Models in PySpark\n",
        "\n",
        "Building models in PySpark looks a little different than you might be used to, and you’ll see terms like Transformer, Estimator, and Param.\n",
        "\n",
        "\n",
        "For an example of linear regression, let’s see if we can predict Fare from Pclass, Age and SibSp."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOO_0NqS-aED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "45bcb788-55d8-4a84-9289-9681c276e267"
      },
      "source": [
        "datam= data.select('Pclass','Age','SibSp','Fare')\n",
        "datam.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+-------+\n",
            "|Pclass| Age|SibSp|   Fare|\n",
            "+------+----+-----+-------+\n",
            "|     3|34.5|    0| 7.8292|\n",
            "|     3|47.0|    1|    7.0|\n",
            "|     2|62.0|    0| 9.6875|\n",
            "|     3|27.0|    0| 8.6625|\n",
            "|     3|22.0|    1|12.2875|\n",
            "|     3|14.0|    0|  9.225|\n",
            "|     3|30.0|    0| 7.6292|\n",
            "|     2|26.0|    1|   29.0|\n",
            "|     3|18.0|    0| 7.2292|\n",
            "|     3|21.0|    2|  24.15|\n",
            "|     3|null|    0| 7.8958|\n",
            "|     1|46.0|    0|   26.0|\n",
            "|     1|23.0|    1|82.2667|\n",
            "|     2|63.0|    1|   26.0|\n",
            "|     1|47.0|    1| 61.175|\n",
            "|     2|24.0|    1|27.7208|\n",
            "|     2|35.0|    0|  12.35|\n",
            "|     3|21.0|    0|  7.225|\n",
            "|     3|27.0|    1|  7.925|\n",
            "|     3|45.0|    0|  7.225|\n",
            "+------+----+-----+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx2x4tdhB54i",
        "colab_type": "text"
      },
      "source": [
        "VectorAssembler\n",
        "\n",
        "The next step is to get our data into a form that PySpark can create a model with. To do this we use something called a VectorAssembler.\n",
        "\n",
        "Here we’ve delineated what features we want our model to use as predictors so that VectorAssembler can take those columns and transform them into a single column (named “predictors”) that contains all the data we want to predict with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLMLqpkMCFDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "inputcols = [\"Pclass\",  \"Age\", \"SibSp\"]\n",
        "assembler = VectorAssembler(inputCols= inputcols, outputCol = \"predictors\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp8HFhErZjqc",
        "colab_type": "text"
      },
      "source": [
        "Here we’ve delineated what features we want our model to use as predictors so that VectorAssembler can take those columns and transform them into a single column (named “predictors”) that contains all the data we want to predict with.\n",
        "\n",
        "What VectorAssembler.transform() does is create a new DataFrame with a new column at the end where each row contains a list of all the features we included in the inputCols parameter when we created the assembler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7BSV1oAZj_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48e77d91-43a2-44d7-b84a-af92d51db975"
      },
      "source": [
        "predictors = assembler.setHandleInvalid(\"skip\").transform(datam)\n",
        "predictors.columns"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pclass', 'Age', 'SibSp', 'Fare', 'predictors']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYTEKsQDaFLW",
        "colab_type": "text"
      },
      "source": [
        "The final step to getting our data ready to be used in a model is to collect the new predictions column we just made and Fare (our target variable) by themselves in a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5Yf4cOSaUPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c3d1cb09-1385-4036-9cd9-4fa394242e06"
      },
      "source": [
        "model_data = predictors.select(\"predictors\", \"Fare\")\n",
        "model_data.show(5,truncate=False)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-------+\n",
            "|predictors    |Fare   |\n",
            "+--------------+-------+\n",
            "|[3.0,34.5,0.0]|7.8292 |\n",
            "|[3.0,47.0,1.0]|7.0    |\n",
            "|[2.0,62.0,0.0]|9.6875 |\n",
            "|[3.0,27.0,0.0]|8.6625 |\n",
            "|[3.0,22.0,1.0]|12.2875|\n",
            "+--------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "167d86KQaaxX",
        "colab_type": "text"
      },
      "source": [
        "Next is to split model_data into a training and testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLv1OFlhakNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data,test_data = model_data.randomSplit([0.8,0.2])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrS4_NJVgbiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=train_data.na.drop()\n",
        "test_data=test_data.na.drop()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQKXTBmZapRq",
        "colab_type": "text"
      },
      "source": [
        "Now to train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-IlOyvFauBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "lr = LinearRegression(featuresCol = 'predictors', labelCol = 'Fare')\n",
        "lrModel = lr.fit(train_data)\n",
        "pred = lrModel.evaluate(test_data)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hbw1KOlhZKo",
        "colab_type": "text"
      },
      "source": [
        "We can also view the final predictions our model made:\n",
        "\n",
        "The object named “pred” is a LinearRegressionSummary object and so to retrieve the DataFrame with predictions we call .predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAYM0MV7hTZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f4bf69c9-2dfa-4640-eff2-6c2fe3bcae2b"
      },
      "source": [
        "pred.predictions.show(5)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-------+-----------------+\n",
            "|    predictors|   Fare|       prediction|\n",
            "+--------------+-------+-----------------+\n",
            "|[1.0,17.0,0.0]|   47.1|85.51984845901637|\n",
            "|[1.0,21.0,0.0]|  26.55|86.53135699305949|\n",
            "|[1.0,22.0,0.0]|61.9792|86.78423412657025|\n",
            "|[1.0,23.0,0.0]|   93.5|87.03711126008105|\n",
            "|[1.0,25.0,1.0]|55.4417|97.49165067104053|\n",
            "+--------------+-------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMSguvyvhfp5",
        "colab_type": "text"
      },
      "source": [
        "Model Evaluating\n",
        "\n",
        "To get more detailed information on how our model performed, we can use RegressionEvaluator which is constructed like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz0jZIPWhwXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "eval = RegressionEvaluator(\n",
        "    labelCol=\"Fare\", \n",
        "    predictionCol=\"prediction\", \n",
        "    metricName=\"rmse\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf_mvXash-rT",
        "colab_type": "text"
      },
      "source": [
        "Let’s compute some statistics for the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR5oeMZViBLt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8a8c15c4-e229-465f-d1a1-c149e9da0143"
      },
      "source": [
        "rmse = eval.evaluate(pred.predictions)\n",
        "print(\"RMSE : \", rmse)\n",
        "\n",
        "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n",
        "print(\"R2 : \", r2)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE :  38.386419215082974\n",
            "R2 :  0.2822345780427099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O25CZPapi6ao",
        "colab_type": "text"
      },
      "source": [
        "From this we can interpret that our model tended to be about 38.386 dollars off from the actual Fare (according to rmse). The r² value for tells us that the predictors in our model are able to account for a little under 30% of the total variability in Fare. This was just a basic practice, and I recommend playing around with the model parameters and features and better Dataset for more practice!"
      ]
    }
  ]
}